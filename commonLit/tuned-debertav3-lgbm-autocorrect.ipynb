{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c41ad",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-11T16:29:49.124235Z",
     "iopub.status.busy": "2023-10-11T16:29:49.123840Z",
     "iopub.status.idle": "2023-10-11T16:30:55.279934Z",
     "shell.execute_reply": "2023-10-11T16:30:55.278787Z"
    },
    "papermill": {
     "duration": 66.164665,
     "end_time": "2023-10-11T16:30:55.282159",
     "exception": false,
     "start_time": "2023-10-11T16:29:49.117494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"/kaggle/input/autocorrect/autocorrect-2.6.1.tar\"\n",
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f2a7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:30:55.293823Z",
     "iopub.status.busy": "2023-10-11T16:30:55.293514Z",
     "iopub.status.idle": "2023-10-11T16:31:12.489198Z",
     "shell.execute_reply": "2023-10-11T16:31:12.488319Z"
    },
    "papermill": {
     "duration": 17.203859,
     "end_time": "2023-10-11T16:31:12.491339",
     "exception": false,
     "start_time": "2023-10-11T16:30:55.287480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from datasets import Dataset,load_dataset, load_from_disk\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import re\n",
    "from autocorrect import Speller\n",
    "from spellchecker import SpellChecker\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "disable_progress_bar()\n",
    "tqdm.pandas()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc3df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:12.502672Z",
     "iopub.status.busy": "2023-10-11T16:31:12.502473Z",
     "iopub.status.idle": "2023-10-11T16:31:12.511288Z",
     "shell.execute_reply": "2023-10-11T16:31:12.510462Z"
    },
    "papermill": {
     "duration": 0.016398,
     "end_time": "2023-10-11T16:31:12.512947",
     "exception": false,
     "start_time": "2023-10-11T16:31:12.496549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a2514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:12.523412Z",
     "iopub.status.busy": "2023-10-11T16:31:12.523234Z",
     "iopub.status.idle": "2023-10-11T16:31:12.527527Z",
     "shell.execute_reply": "2023-10-11T16:31:12.526714Z"
    },
    "papermill": {
     "duration": 0.011473,
     "end_time": "2023-10-11T16:31:12.529197",
     "exception": false,
     "start_time": "2023-10-11T16:31:12.517724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name=\"debertav3base\"\n",
    "    learning_rate=1.6e-5\n",
    "    weight_decay=0.03\n",
    "    hidden_dropout_prob=0.007\n",
    "    attention_probs_dropout_prob=0.007\n",
    "    num_train_epochs=5\n",
    "    n_splits=4\n",
    "    batch_size=12\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aca163",
   "metadata": {
    "papermill": {
     "duration": 0.004544,
     "end_time": "2023-10-11T16:31:12.538527",
     "exception": false,
     "start_time": "2023-10-11T16:31:12.533983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b695f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:12.548974Z",
     "iopub.status.busy": "2023-10-11T16:31:12.548757Z",
     "iopub.status.idle": "2023-10-11T16:31:12.678903Z",
     "shell.execute_reply": "2023-10-11T16:31:12.678067Z"
    },
    "papermill": {
     "duration": 0.137705,
     "end_time": "2023-10-11T16:31:12.680969",
     "exception": false,
     "start_time": "2023-10-11T16:31:12.543264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/commonlit-evaluate-student-summaries/\"\n",
    "\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79616fa5",
   "metadata": {
    "papermill": {
     "duration": 0.004687,
     "end_time": "2023-10-11T16:31:12.690864",
     "exception": false,
     "start_time": "2023-10-11T16:31:12.686177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess\n",
    "[Using features]\n",
    "Text Length, Length Ratio, Word Overlap, N-grams Co-occurrence (count, ratio), Quotes Overlap, Grammar Check (spelling: pyspellchecker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ffa6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:12.701881Z",
     "iopub.status.busy": "2023-10-11T16:31:12.701663Z",
     "iopub.status.idle": "2023-10-11T16:31:14.455146Z",
     "shell.execute_reply": "2023-10-11T16:31:14.454224Z"
    },
    "papermill": {
     "duration": 1.761752,
     "end_time": "2023-10-11T16:31:14.457339",
     "exception": false,
     "start_time": "2023-10-11T16:31:12.695587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                ) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.twd = TreebankWordDetokenizer()\n",
    "        self.STOP_WORDS = set(stopwords.words('english'))\n",
    "        \n",
    "        self.spacy_ner_model = spacy.load('en_core_web_sm',)\n",
    "        self.speller = Speller(lang='en')\n",
    "        self.spellchecker = SpellChecker() \n",
    "        \n",
    "    def word_overlap_count(self, row):\n",
    "        \"\"\" intersection(prompt_text, text) \"\"\"        \n",
    "        def check_is_stop_word(word):\n",
    "            return word in self.STOP_WORDS\n",
    "        \n",
    "        prompt_words = row['prompt_tokens']\n",
    "        summary_words = row['summary_tokens']\n",
    "        if self.STOP_WORDS:\n",
    "            prompt_words = list(filter(check_is_stop_word, prompt_words))\n",
    "            summary_words = list(filter(check_is_stop_word, summary_words))\n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "    \n",
    "    def proper_nouns_overlap_count(self, row):\n",
    "        prompt_words  = pos_tag(row['prompt_tokens'])\n",
    "        summary_words = pos_tag(row['summary_tokens'])\n",
    "        \n",
    "        prompt_words  = [word for word,pos in prompt_words if pos == 'NNP']\n",
    "        summary_words = [word for word,pos in summary_words if pos == 'NNP']\n",
    "        \n",
    "        return len(set(prompt_words).intersection(set(summary_words)))\n",
    "    \n",
    "    def proper_nouns(self, row):\n",
    "        prompt_words = pos_tag(row['prompt_text'].split())\n",
    "        prompt_words = [word for word,pos in prompt_words if pos == 'NNP']\n",
    "        return prompt_words\n",
    "    \n",
    "    def meaningful_phrases(self, row):\n",
    "        model = self.spacy_ner_model\n",
    "        \n",
    "        prompt  = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "        \n",
    "        prompt  = set([token.text for token in prompt.ents])\n",
    "        summary = set([token.text for token in summary.ents])\n",
    "        \n",
    "        return len(prompt.intersection(summary))\n",
    "    \n",
    "    def tfidf(self, row):\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform([row['prompt_text'], row['text']])\n",
    "\n",
    "        # Calculating the cosine measure of similarity between two texts\n",
    "        return cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "    \n",
    "    def litSimilarity(self, row):\n",
    "        model = self.spacy_ner_model\n",
    "        text   = model(row['text'][0])\n",
    "        prompt = model(row['prompt_text'][0])\n",
    "\n",
    "        return text.similarity(prompt)\n",
    "            \n",
    "    def ngrams(self, token, n):\n",
    "        # Use the zip function to help us generate n-grams\n",
    "        # Concatentate the tokens into ngrams and return\n",
    "        ngrams = zip(*[token[i:] for i in range(n)])\n",
    "        return [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "    def ngram_co_occurrence(self, row, n: int) -> int:\n",
    "        # Generate n-grams for the original text and summary\n",
    "        original_ngrams = set(self.ngrams(row['prompt_tokens'], n))\n",
    "        summary_ngrams = set(self.ngrams(row['summary_tokens'], n))\n",
    "\n",
    "        # Calculate the number of common n-grams\n",
    "        common_ngrams = original_ngrams.intersection(summary_ngrams)\n",
    "        return len(common_ngrams)\n",
    "    \n",
    "    def ner_overlap_count(self, row, mode:str):\n",
    "        model = self.spacy_ner_model\n",
    "        def clean_ners(ner_list):\n",
    "            return set([(ner[0].lower(), ner[1]) for ner in ner_list])\n",
    "        prompt = model(row['prompt_text'])\n",
    "        summary = model(row['text'])\n",
    "\n",
    "        if \"spacy\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.label_) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.label_) for token in summary.ents])\n",
    "        elif \"stanza\" in str(model):\n",
    "            prompt_ner = set([(token.text, token.type) for token in prompt.ents])\n",
    "            summary_ner = set([(token.text, token.type) for token in summary.ents])\n",
    "        else:\n",
    "            raise Exception(\"Model not supported\")\n",
    "\n",
    "        prompt_ner = clean_ners(prompt_ner)\n",
    "        summary_ner = clean_ners(summary_ner)\n",
    "\n",
    "        intersecting_ners = prompt_ner.intersection(summary_ner)\n",
    "        \n",
    "        ner_dict = dict(Counter([ner[1] for ner in intersecting_ners]))\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            return ner_dict\n",
    "        elif mode == \"test\":\n",
    "            return {key: ner_dict.get(key) for key in self.ner_keys}\n",
    "\n",
    "    \n",
    "    def quotes_count(self, row):\n",
    "        summary = row['text']\n",
    "        text = row['prompt_text']\n",
    "        quotes_from_summary = re.findall(r'\"([^\"]*)\"', summary)\n",
    "        if len(quotes_from_summary)>0:\n",
    "            return [quote in text for quote in quotes_from_summary].count(True)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def spelling(self, text):\n",
    "        \n",
    "        wordlist=text.split()\n",
    "        amount_miss = len(list(self.spellchecker.unknown(wordlist)))\n",
    "\n",
    "        return amount_miss\n",
    "    \n",
    "    def add_spelling_dictionary(self, tokens: List[str]) -> List[str]:\n",
    "        \"\"\"dictionary update for pyspell checker and autocorrect\"\"\"\n",
    "        self.spellchecker.word_frequency.load_words(tokens)\n",
    "        self.speller.nlp_data.update({token:1000 for token in tokens})\n",
    "        \n",
    "    def add_question2text(self, row, prompts):\n",
    "        q = prompts[prompts['prompt_id'] == row['prompt_id']]['prompt_question'].iloc[0]\n",
    "        row['text'] = f\"Question: {q} \\n Answer: {row['text']}\"\n",
    "        return row\n",
    "    \n",
    "    def run(self, \n",
    "            prompts: pd.DataFrame,\n",
    "            summaries:pd.DataFrame,\n",
    "            mode:str\n",
    "        ) -> pd.DataFrame:\n",
    "        \n",
    "        # before merge preprocess\n",
    "        prompts[\"prompt_length\"] = prompts[\"prompt_text\"].apply(lambda x: len(word_tokenize(x)))\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(lambda x: word_tokenize(x))\n",
    "        \n",
    "        summaries = summaries.progress_apply(self.add_question2text,args=(prompts,), axis=1)\n",
    "\n",
    "        summaries[\"summary_length\"] = summaries[\"text\"].apply(lambda x: len(word_tokenize(x)))\n",
    "        summaries[\"summary_tokens\"] = summaries[\"text\"].apply(lambda x: word_tokenize(x))\n",
    "        \n",
    "        # Add prompt tokens into spelling checker dictionary\n",
    "        prompts[\"prompt_tokens\"].apply(lambda x: self.add_spelling_dictionary(x))\n",
    "        \n",
    "        # fix misspelling\n",
    "        summaries[\"fixed_summary_text\"] = summaries[\"text\"].progress_apply(lambda x: self.speller(x))\n",
    "        \n",
    "        stemmer = PorterStemmer()\n",
    "        prompts[\"prompt_tokens\"] = prompts[\"prompt_text\"].apply(lambda x: stemmer.stem(x))\n",
    "        summaries[\"fixed_summary_text\"] = summaries[\"fixed_summary_text\"].apply(lambda x: stemmer.stem(x))\n",
    "        \n",
    "        # count misspelling\n",
    "        summaries[\"splling_err_num\"] = summaries[\"text\"].progress_apply(self.spelling)\n",
    "        \n",
    "        # merge prompts and summaries\n",
    "        input_df = summaries.merge(prompts, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "        # after merge preprocess\n",
    "        #input_df['length_ratio'] = input_df['summary_length'] / input_df['prompt_length']\n",
    "        \n",
    "        #input_df['word_overlap_count'] = input_df.progress_apply(self.word_overlap_count, axis=1)\n",
    "        input_df['bigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence,args=(2,), axis=1 \n",
    "        )\n",
    "        input_df['bigram_overlap_ratio'] = input_df['bigram_overlap_count'] / (input_df['summary_length'] - 1)\n",
    "        \n",
    "        input_df['trigram_overlap_count'] = input_df.progress_apply(\n",
    "            self.ngram_co_occurrence, args=(3,), axis=1\n",
    "        )\n",
    "        input_df['trigram_overlap_ratio'] = input_df['trigram_overlap_count'] / (input_df['summary_length'] - 2)\n",
    "        \n",
    "        input_df['quotes_count'] = input_df.progress_apply(self.quotes_count, axis=1)\n",
    "        \n",
    "        input_df['proper_names_count'] = input_df.progress_apply(self.proper_nouns_overlap_count, axis=1)\n",
    "        input_df['tfidf']              = input_df.progress_apply(self.tfidf, axis=1)\n",
    "        input_df['meaningful_phrases'] = input_df.progress_apply(self.meaningful_phrases, axis=1)\n",
    "        input_df['similarity']         = input_df.progress_apply(self.litSimilarity, axis=1)\n",
    "        \n",
    "        return input_df.drop(columns=[\"summary_tokens\", \"prompt_tokens\"])\n",
    "    \n",
    "preprocessor = Preprocessor(model_name=CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c60645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:14.468567Z",
     "iopub.status.busy": "2023-10-11T16:31:14.468361Z",
     "iopub.status.idle": "2023-10-11T16:31:27.425353Z",
     "shell.execute_reply": "2023-10-11T16:31:27.424206Z"
    },
    "papermill": {
     "duration": 12.964591,
     "end_time": "2023-10-11T16:31:27.427063",
     "exception": false,
     "start_time": "2023-10-11T16:31:14.462472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    train = preprocessor.run(prompts_train, summaries_train, mode=\"train\")\n",
    "else:\n",
    "    train = preprocessor.run(prompts_train[:30], summaries_train[:30], mode=\"train\")\n",
    "    print(train.head())\n",
    "\n",
    "test = preprocessor.run(prompts_test, summaries_test, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d079fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.448902Z",
     "iopub.status.busy": "2023-10-11T16:31:27.448550Z",
     "iopub.status.idle": "2023-10-11T16:31:27.474041Z",
     "shell.execute_reply": "2023-10-11T16:31:27.473243Z"
    },
    "papermill": {
     "duration": 0.038183,
     "end_time": "2023-10-11T16:31:27.475884",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.437701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f847dc",
   "metadata": {
    "papermill": {
     "duration": 0.01073,
     "end_time": "2023-10-11T16:31:27.497786",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.487056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dddabeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.520595Z",
     "iopub.status.busy": "2023-10-11T16:31:27.519790Z",
     "iopub.status.idle": "2023-10-11T16:31:27.526160Z",
     "shell.execute_reply": "2023-10-11T16:31:27.525386Z"
    },
    "papermill": {
     "duration": 0.019485,
     "end_time": "2023-10-11T16:31:27.527790",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.508305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\": rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \"\"\"\n",
    "    Calculates mean columnwise root mean squared error\n",
    "    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n",
    "    \"\"\"\n",
    "    preds, labels = eval_pred\n",
    "\n",
    "    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "\n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse,\n",
    "    }\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred)**(1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred)**(1/2)\n",
    "    \n",
    "    return (content_score + wording_score)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b532559",
   "metadata": {
    "papermill": {
     "duration": 0.009938,
     "end_time": "2023-10-11T16:31:27.548131",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.538193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Deberta Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a514d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.569875Z",
     "iopub.status.busy": "2023-10-11T16:31:27.569646Z",
     "iopub.status.idle": "2023-10-11T16:31:27.585593Z",
     "shell.execute_reply": "2023-10-11T16:31:27.584848Z"
    },
    "papermill": {
     "duration": 0.029084,
     "end_time": "2023-10-11T16:31:27.587280",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.558196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentScoreRegressor:\n",
    "    def __init__(self, \n",
    "                model_name: str,\n",
    "                model_dir: str,\n",
    "                target: str,\n",
    "                hidden_dropout_prob: float,\n",
    "                attention_probs_dropout_prob: float,\n",
    "                max_length: int,\n",
    "                ):\n",
    "        self.inputs = [\"prompt_text\", \"prompt_title\", \"prompt_question\", \"fixed_summary_text\"]\n",
    "        self.input_col = \"input\"\n",
    "        \n",
    "        self.text_cols = [self.input_col] \n",
    "        self.target = target\n",
    "        self.target_cols = [target]\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        self.model_config = AutoConfig.from_pretrained(f\"/kaggle/input/{model_name}\")\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\": 1,\n",
    "            \"problem_type\": \"regression\",\n",
    "        })\n",
    "        \n",
    "        seed_everything(seed=42)\n",
    "\n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "\n",
    "\n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[self.target]]\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "    \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[self.input_col],\n",
    "                         padding=False,\n",
    "                         truncation=True,\n",
    "                         max_length=self.max_length)\n",
    "        return tokenized\n",
    "        \n",
    "    def train(self, \n",
    "            fold: int,\n",
    "            train_df: pd.DataFrame,\n",
    "            valid_df: pd.DataFrame,\n",
    "            batch_size: int,\n",
    "            learning_rate: float,\n",
    "            weight_decay: float,\n",
    "            num_train_epochs: float,\n",
    "            save_steps: int,\n",
    "        ) -> None:\n",
    "        \"\"\"fine-tuning\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        train_df[self.input_col] = (\n",
    "                    train_df[\"prompt_title\"] + sep \n",
    "                    + train_df[\"prompt_question\"] + sep \n",
    "                    + train_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "\n",
    "        valid_df[self.input_col] = (\n",
    "                    valid_df[\"prompt_title\"] + sep \n",
    "                    + valid_df[\"prompt_question\"] + sep \n",
    "                    + valid_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        \n",
    "        train_df = train_df[[self.input_col] + self.target_cols]\n",
    "        valid_df = valid_df[[self.input_col] + self.target_cols]\n",
    "        \n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            f\"/kaggle/input/{self.model_name}\", \n",
    "            config=self.model_config\n",
    "        )\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False) \n",
    "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False) \n",
    "    \n",
    "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
    "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
    "\n",
    "        # eg. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            load_best_model_at_end=True, # select best model\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            report_to='none',\n",
    "            greater_is_better=False,\n",
    "            save_strategy=\"steps\",\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=save_steps,\n",
    "            save_steps=save_steps,\n",
    "            metric_for_best_model=\"rmse\",\n",
    "            save_total_limit=1\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=training_args,\n",
    "            train_dataset=train_tokenized_datasets,\n",
    "            eval_dataset=val_tokenized_datasets,\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=self.data_collator\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "        \n",
    "        model_content.save_pretrained(self.model_dir)\n",
    "        self.tokenizer.save_pretrained(self.model_dir)\n",
    "\n",
    "        \n",
    "    def predict(self, \n",
    "                test_df: pd.DataFrame,\n",
    "                fold: int,\n",
    "               ):\n",
    "        \"\"\"predict content score\"\"\"\n",
    "        \n",
    "        sep = self.tokenizer.sep_token\n",
    "        in_text = (\n",
    "                    test_df[\"prompt_title\"] + sep \n",
    "                    + test_df[\"prompt_question\"] + sep \n",
    "                    + test_df[\"fixed_summary_text\"]\n",
    "                  )\n",
    "        test_df[self.input_col] = in_text\n",
    "\n",
    "        test_ = test_df[[self.input_col]]\n",
    "    \n",
    "        test_dataset = Dataset.from_pandas(test_, preserve_index=False) \n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "\n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(f\"{self.model_dir}\")\n",
    "        model_content.eval()\n",
    "        \n",
    "        # e.g. \"bert/fold_0/\"\n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold)) \n",
    "\n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train = False,\n",
    "            do_predict = True,\n",
    "            per_device_eval_batch_size = 4,   \n",
    "            dataloader_drop_last = False,\n",
    "        )\n",
    "\n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "                      model = model_content, \n",
    "                      tokenizer=self.tokenizer,\n",
    "                      data_collator=self.data_collator,\n",
    "                      args = test_args)\n",
    "\n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfba1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.609598Z",
     "iopub.status.busy": "2023-10-11T16:31:27.609417Z",
     "iopub.status.idle": "2023-10-11T16:31:27.620018Z",
     "shell.execute_reply": "2023-10-11T16:31:27.619137Z"
    },
    "papermill": {
     "duration": 0.02366,
     "end_time": "2023-10-11T16:31:27.621716",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.598056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_by_fold(\n",
    "        train_df: pd.DataFrame,\n",
    "        model_name: str,\n",
    "        target:str,\n",
    "        save_each_model: bool,\n",
    "        n_splits: int,\n",
    "        batch_size: int,\n",
    "        learning_rate: int,\n",
    "        hidden_dropout_prob: float,\n",
    "        attention_probs_dropout_prob: float,\n",
    "        weight_decay: float,\n",
    "        num_train_epochs: int,\n",
    "        save_steps: int,\n",
    "        max_length:int\n",
    "    ):\n",
    "\n",
    "    # delete old model files\n",
    "    if os.path.exists(model_name):\n",
    "        shutil.rmtree(model_name)\n",
    "    \n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        train_data = train_df[train_df[\"fold\"] != fold]\n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        csr.train(\n",
    "            fold=fold,\n",
    "            train_df=train_data,\n",
    "            valid_df=valid_data, \n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "\n",
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"predict oof data\"\"\"\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "        \n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=valid_data, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
    "\n",
    "    return train_df\n",
    "    \n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=test_df, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
    "    \n",
    "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16814a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.643639Z",
     "iopub.status.busy": "2023-10-11T16:31:27.642999Z",
     "iopub.status.idle": "2023-10-11T16:31:27.649390Z",
     "shell.execute_reply": "2023-10-11T16:31:27.648585Z"
    },
    "papermill": {
     "duration": 0.019204,
     "end_time": "2023-10-11T16:31:27.651087",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.631883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    for target in [\"content\", \"wording\"]:\n",
    "        train_by_fold(\n",
    "            train,\n",
    "            model_name=CFG.model_name,\n",
    "            save_each_model=False,\n",
    "            target=target,\n",
    "            learning_rate=CFG.learning_rate,\n",
    "            hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "            weight_decay=CFG.weight_decay,\n",
    "            num_train_epochs=CFG.num_train_epochs,\n",
    "            n_splits=CFG.n_splits,\n",
    "            batch_size=CFG.batch_size,\n",
    "            save_steps=CFG.save_steps,\n",
    "            max_length=CFG.max_length\n",
    "        )\n",
    "\n",
    "\n",
    "        train = validate(\n",
    "            train,\n",
    "            target=target,\n",
    "            save_each_model=False,\n",
    "            model_name=CFG.model_name,\n",
    "            hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "            max_length=CFG.max_length\n",
    "        )\n",
    "\n",
    "        rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
    "        print(f\"cv {target} rmse: {rmse}\")\n",
    "\n",
    "        test = predict(\n",
    "            test,\n",
    "            target=target,\n",
    "            save_each_model=False,\n",
    "            model_name=CFG.model_name,\n",
    "            hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "            max_length=CFG.max_length\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be6dac",
   "metadata": {
    "papermill": {
     "duration": 0.010039,
     "end_time": "2023-10-11T16:31:27.671366",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.661327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa77def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.693349Z",
     "iopub.status.busy": "2023-10-11T16:31:27.692673Z",
     "iopub.status.idle": "2023-10-11T16:31:27.697106Z",
     "shell.execute_reply": "2023-10-11T16:31:27.696301Z"
    },
    "papermill": {
     "duration": 0.01733,
     "end_time": "2023-10-11T16:31:27.698790",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.681460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "targets = [\"content\", \"wording\"]\n",
    "\n",
    "drop_columns = [\"fold\", \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\"\n",
    "               ] + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a17241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.720558Z",
     "iopub.status.busy": "2023-10-11T16:31:27.719879Z",
     "iopub.status.idle": "2023-10-11T16:31:27.727249Z",
     "shell.execute_reply": "2023-10-11T16:31:27.726478Z"
    },
    "papermill": {
     "duration": 0.019968,
     "end_time": "2023-10-11T16:31:27.728877",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.708909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    for target in targets:\n",
    "        models = []\n",
    "\n",
    "        for fold in range(CFG.n_splits):\n",
    "\n",
    "            X_train_cv = train[train[\"fold\"] != fold].drop(columns=drop_columns)\n",
    "            y_train_cv = train[train[\"fold\"] != fold][target]\n",
    "\n",
    "            X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "            y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "            dtrain = lgb.Dataset(X_train_cv, label=y_train_cv)\n",
    "            dval = lgb.Dataset(X_eval_cv, label=y_eval_cv)\n",
    "\n",
    "            params = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'random_state': 42,\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'learning_rate': 0.048,\n",
    "                'max_depth': 3,\n",
    "                'lambda_l1': 0.0,\n",
    "                'lambda_l2': 0.011\n",
    "            }\n",
    "\n",
    "            evaluation_results = {}\n",
    "            model = lgb.train(params,\n",
    "                              num_boost_round=10000,\n",
    "                                #categorical_feature = categorical_features,\n",
    "                              valid_names=['train', 'valid'],\n",
    "                              train_set=dtrain,\n",
    "                              valid_sets=dval,\n",
    "                              callbacks=[\n",
    "                                  lgb.early_stopping(stopping_rounds=30, verbose=True),\n",
    "                                   lgb.log_evaluation(100),\n",
    "                                  lgb.callback.record_evaluation(evaluation_results)\n",
    "                                ],\n",
    "                              )\n",
    "            models.append(model)\n",
    "\n",
    "        model_dict[target] = models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d306b2",
   "metadata": {
    "papermill": {
     "duration": 0.010388,
     "end_time": "2023-10-11T16:31:27.749647",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.739259",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434cbe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.774234Z",
     "iopub.status.busy": "2023-10-11T16:31:27.773494Z",
     "iopub.status.idle": "2023-10-11T16:31:27.780136Z",
     "shell.execute_reply": "2023-10-11T16:31:27.778851Z"
    },
    "papermill": {
     "duration": 0.021292,
     "end_time": "2023-10-11T16:31:27.782692",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.761400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cv\n",
    "rmses = []\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    for target in targets:\n",
    "        models = model_dict[target]\n",
    "\n",
    "        preds = []\n",
    "        trues = []\n",
    "\n",
    "        for fold, model in enumerate(models):\n",
    "            X_eval_cv = train[train[\"fold\"] == fold].drop(columns=drop_columns)\n",
    "            y_eval_cv = train[train[\"fold\"] == fold][target]\n",
    "\n",
    "            pred = model.predict(X_eval_cv)\n",
    "\n",
    "            trues.extend(y_eval_cv)\n",
    "            preds.extend(pred)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "        #print(f\"{target}_rmse : {rmse}\")\n",
    "        rmses = rmses + [rmse]\n",
    "\n",
    "    print(f\"mcrmse : {sum(rmses) / len(rmses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a2ead",
   "metadata": {
    "papermill": {
     "duration": 0.010328,
     "end_time": "2023-10-11T16:31:27.804235",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.793907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d34d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.827272Z",
     "iopub.status.busy": "2023-10-11T16:31:27.826988Z",
     "iopub.status.idle": "2023-10-11T16:31:27.832201Z",
     "shell.execute_reply": "2023-10-11T16:31:27.831225Z"
    },
    "papermill": {
     "duration": 0.019799,
     "end_time": "2023-10-11T16:31:27.834311",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.814512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "                #\"fold\", \n",
    "                \"student_id\", \"prompt_id\", \"text\", \"fixed_summary_text\",\n",
    "                \"prompt_question\", \"prompt_title\", \n",
    "                \"prompt_text\",\n",
    "                \"input\"\n",
    "               ] + [\n",
    "                f\"content_pred_{i}\" for i in range(CFG.n_splits)\n",
    "                ] + [\n",
    "                f\"wording_pred_{i}\" for i in range(CFG.n_splits)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b19d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.860217Z",
     "iopub.status.busy": "2023-10-11T16:31:27.859424Z",
     "iopub.status.idle": "2023-10-11T16:31:27.865500Z",
     "shell.execute_reply": "2023-10-11T16:31:27.864627Z"
    },
    "papermill": {
     "duration": 0.02102,
     "end_time": "2023-10-11T16:31:27.867403",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.846383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    for target in targets:\n",
    "        models = model_dict[target]\n",
    "        preds = []\n",
    "\n",
    "        for fold, model in enumerate(models):\n",
    "            X_eval_cv = test.drop(columns=drop_columns)\n",
    "\n",
    "            pred = model.predict(X_eval_cv)\n",
    "            preds.append(pred)\n",
    "\n",
    "        pred_dict[target] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b894356",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.893211Z",
     "iopub.status.busy": "2023-10-11T16:31:27.892710Z",
     "iopub.status.idle": "2023-10-11T16:31:27.897851Z",
     "shell.execute_reply": "2023-10-11T16:31:27.896874Z"
    },
    "papermill": {
     "duration": 0.020205,
     "end_time": "2023-10-11T16:31:27.899713",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.879508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    for target in targets:\n",
    "        preds = pred_dict[target]\n",
    "        for i, pred in enumerate(preds):\n",
    "            test[f\"{target}_pred_{i}\"] = pred\n",
    "\n",
    "        test[target] = test[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4e386",
   "metadata": {
    "papermill": {
     "duration": 0.01192,
     "end_time": "2023-10-11T16:31:27.923635",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.911715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d326c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-11T16:31:27.950195Z",
     "iopub.status.busy": "2023-10-11T16:31:27.949476Z",
     "iopub.status.idle": "2023-10-11T16:31:27.957381Z",
     "shell.execute_reply": "2023-10-11T16:31:27.956420Z"
    },
    "papermill": {
     "duration": 0.023634,
     "end_time": "2023-10-11T16:31:27.959553",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.935919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)\n",
    "else:\n",
    "    sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999af5d1",
   "metadata": {
    "papermill": {
     "duration": 0.011523,
     "end_time": "2023-10-11T16:31:27.984410",
     "exception": false,
     "start_time": "2023-10-11T16:31:27.972887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "CV result is like this.\n",
    "\n",
    "| | content rmse |wording rmse | mcrmse | LB| |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "|baseline| 0.494 | 0.630 | 0.562 | 0.509 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models)|\n",
    "| use title and question field | 0.476| 0.619 | 0.548 | 0.508 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-w-prompt-title-question-fields) |\n",
    "| Debertav3 + LGBM | 0.451 | 0.591 | 0.521 | 0.461 | [link](https://www.kaggle.com/code/tsunotsuno/debertav3-lgbm-with-feature-engineering) |\n",
    "| Debertav3 + LGBM with spell autocorrect | 0.448 | 0.581 | 0.514 | 0.459 |nogawanogawa's original code\n",
    "| Debertav3 + LGBM with spell autocorrect and tuning | 0.442 | 0.566 | 0.504 | 0.453 | this notebook |\n",
    "\n",
    "The CV values improved slightly, and the LB value is improved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 110.57186,
   "end_time": "2023-10-11T16:31:31.093754",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-11T16:29:40.521894",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
